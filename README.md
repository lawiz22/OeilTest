# ðŸ‘ï¸ L'Å’IL â€” Data Quality & Integrity Framework

> **Un moteur de validation configurable, traÃ§able et rÃ©utilisable â€” enterprise-wide.**

L'Å’IL est un framework de contrÃ´le qualitÃ© des donnÃ©es conÃ§u pour les environnements Azure. Il orchestre la validation de volumes, de SLA, d'intÃ©gritÃ© et de coÃ»ts Ã  travers Azure Data Factory, Synapse, Azure SQL et Log Analytics.

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Azure Data  â”‚â”€â”€â”€â”€â–¶â”‚  Azure SQL   â”‚â—€â”€â”€â”€â”€â”‚   Log Analytics  â”‚
â”‚   Factory    â”‚     â”‚  (vigie_ctrl â”‚     â”‚   (KQL Logs)     â”‚
â”‚  (Pipelines) â”‚     â”‚   + policy)  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚
       â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ADLS Gen2  â”‚     â”‚   Synapse    â”‚
â”‚  (Bronze CSV â”‚     â”‚  (Compute    â”‚
â”‚   + CTRL)    â”‚     â”‚   avancÃ©)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Composant         | RÃ´le                                          |
|-------------------|-----------------------------------------------|
| **ADF**           | Orchestration des pipelines d'ingestion        |
| **Azure SQL**     | Source de vÃ©ritÃ© (vigie_ctrl, policies)         |
| **Synapse**       | Compute ponctuel pour validations avancÃ©es     |
| **Log Analytics** | KQL pour logs ADF / SLA                        |
| **ADLS Gen2**     | Stockage Bronze (CSV + fichiers CTRL JSON)     |
| **Python**        | GÃ©nÃ©ration de donnÃ©es, extraction, SLA compute |

---

## ðŸ“ Structure du Projet

```
OeilTest/
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ core/                      # Modules de base
â”‚   â”‚   â”œâ”€â”€ extractor.py           # Extraction + CTRL + SHA256
â”‚   â”‚   â”œâ”€â”€ schemas.py             # Data generators (faker)
â”‚   â”‚   â”œâ”€â”€ sqlite_schema.py       # SQLite local schema
â”‚   â”‚   â”œâ”€â”€ sql_writer.py          # SQLite data writer
â”‚   â”‚   â””â”€â”€ vigie_faker.py         # GÃ©nÃ©rateur de faux runs vigie
â”‚   â”œâ”€â”€ runners/                   # Scripts d'exÃ©cution
â”‚   â”‚   â”œâ”€â”€ run_extractions.py     # GÃ©nÃ¨re CSV + CTRL bronze
â”‚   â”‚   â”œâ”€â”€ run_vigie_faker.py     # Injecte des runs vigie simulÃ©s
â”‚   â”‚   â”œâ”€â”€ run_sla_compute.py     # Calcul SLA via SP
â”‚   â”‚   â”œâ”€â”€ run_vigie_sla_finalize.py  # Finalisation SLA + alertes
â”‚   â”‚   â”œâ”€â”€ reset_oeil_environment.py  # Reset complet (DB + fichiers)
â”‚   â”‚   â”œâ”€â”€ create_schema.py       # CrÃ©ation schÃ©ma Azure/SQLite
â”‚   â”‚   â””â”€â”€ ok_ctrl.py             # Insert CTRL manuel
â”‚   â””â”€â”€ generators/                # GÃ©nÃ©rateurs standalone
â”‚       â”œâ”€â”€ generate_fake_data.py
â”‚       â”œâ”€â”€ fake_data_generator.py
â”‚       â””â”€â”€ ctrl_generator.py
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ tables/                    # DDL (CREATE TABLE)
â”‚   â”‚   â”œâ”€â”€ vigie_ctrl.sql         # Table principale des runs
â”‚   â”‚   â”œâ”€â”€ vigie_policy_table.sql # Policy par dataset (v2)
â”‚   â”‚   â”œâ”€â”€ vigie_policy_test.sql  # Tests par policy (v2)
â”‚   â”‚   â”œâ”€â”€ vigie_integrity_result.sql # RÃ©sultats intÃ©gritÃ© (v2)
â”‚   â”‚   â”œâ”€â”€ ctrl_file_index.sql    # Index fichiers ingÃ©rÃ©s (re-runs)
â”‚   â”‚   â”œâ”€â”€ sla_profile.sql        # Profil SLA par dataset (futur)
â”‚   â”‚   â”œâ”€â”€ sla_profile_execution_type.sql # Profil SLA par type exec (actif)
â”‚   â”‚   â”œâ”€â”€ synapse_rowcount_cache.sql # Cache row count Synapse (tampon)
â”‚   â”‚   â”œâ”€â”€ clients.sql
â”‚   â”‚   â”œâ”€â”€ accounts.sql
â”‚   â”‚   â”œâ”€â”€ transactions.sql
â”‚   â”‚   â””â”€â”€ contracts.sql
â”‚   â””â”€â”€ procedures/                # Stored Procedures
â”‚       â”œâ”€â”€ SP_Compute_SLA_OEIL.sql
â”‚       â”œâ”€â”€ SP_Compute_SLA_ADF.sql
â”‚       â”œâ”€â”€ SP_Compute_SLA_SYNAPSE.sql
â”‚       â””â”€â”€ SP_Compute_SLA_Vigie.sql
â”œâ”€â”€ adf/                           # Pipeline JSON ADF
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ dataset_schedule.json      # Schedule par dataset
â”‚   â””â”€â”€ sample_ctrl.json           # Exemple fichier CTRL v2
â”œâ”€â”€ azcopy_uploader.py             # Upload Bronze â†’ ADLS
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸŽ¯ CapacitÃ©s

### v1 â€” En production
| ContrÃ´le              | Description                                          |
|-----------------------|------------------------------------------------------|
| **Row Count**         | Comparaison expected vs actual (ADF ingestion)       |
| **SLA OEIL/ADF/Synapse** | Calcul automatique des buckets (FAST/SLOW/VERY_SLOW) |
| **Volume Status**     | OK / LOW / ANOMALY                                   |
| **Alert Level**       | NO_ALERT / INFO / WARNING / CRITICAL                 |
| **CoÃ»t Synapse**      | Estimation en CAD basÃ©e sur la durÃ©e                 |
| **Hash SHA256**       | Hash canonique dÃ©terministique du payload             |

### v2 â€” IntÃ©gritÃ© configurable (en cours)
| ContrÃ´le              | Description                                          |
|-----------------------|------------------------------------------------------|
| **Min/Max**           | Validation min/max sur colonne configurÃ©e             |
| **Checksum**          | SHA256/MD5 sur colonne configurÃ©e                     |
| **Null Count**        | Validation de nullabilitÃ©                             |
| **Delta Previous**    | Comparaison avec le run prÃ©cÃ©dent                     |
| **Policy Engine**     | Activation/dÃ©sactivation dynamique par dataset        |

---

## ðŸ“‹ Fichier CTRL (v2)

Chaque run produit un fichier JSON CTRL stockÃ© dans le lac :

```json
{
  "ctrl_id": "accounts_2026-10-08_Q",
  "dataset": "accounts",
  "periodicity": "Q",
  "extraction_date": "2026-10-08",
  "volume": {
    "expected_rows": 1261,
    "actual_rows": 1261,
    "delta": 0
  },
  "integrity": {
    "min_max": {
      "column": "account_id",
      "min": 100001,
      "max": 198772
    },
    "checksum": {
      "column": "account_id",
      "algorithm": "SHA256",
      "value": "ab3290c9..."
    }
  }
}
```

---

## ðŸ›ï¸ ModÃ¨le de Policy (v2)

La source de vÃ©ritÃ© des policies est SQL. Elles sont exportables en JSON vers le lac.

```
vigie_policy_table          vigie_policy_test
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ dataset (PK)     â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ dataset (FK)             â”‚
â”‚ environment      â”‚        â”‚ test_type                â”‚
â”‚ enabled          â”‚        â”‚ enabled                  â”‚
â”‚ synapse_allowed  â”‚        â”‚ frequency (DAILY/WEEKLY)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚ target_column            â”‚
                            â”‚ algorithm                â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚ vigie_integrity_result    â”‚
                            â”‚ ctrl_id + test_type       â”‚
                            â”‚ result_status (OK/FAIL)   â”‚
                            â”‚ expected vs actual        â”‚
                            â”‚ compute_engine            â”‚
                            â”‚ compute_cost              â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸš€ Quick Start

### PrÃ©requis
- Python 3.12+
- ODBC Driver 18 for SQL Server
- Azure SQL Database
- AzCopy (pour upload ADLS)

### Installation

```bash
python -m venv .venv2
.venv2\Scripts\activate
pip install -r requirements.txt
```

### ExÃ©cuter une extraction (fake data)

```bash
python -m python.runners.run_extractions
```

### Injecter des runs vigie simulÃ©s

```bash
python -m python.runners.run_vigie_faker
```

### Calculer les SLA

```bash
python -m python.runners.run_sla_compute
```

### Finaliser SLA + Alertes

```bash
python -m python.runners.run_vigie_sla_finalize
```

### Upload Bronze â†’ ADLS

```bash
python azcopy_uploader.py
```

### Reset complet de l'environnement

```bash
python -m python.runners.reset_oeil_environment
```

---

## âš¡ Contraintes de Design

| Contrainte                          | Approche                                            |
|-------------------------------------|-----------------------------------------------------|
| Synapse = coÃ»teux                   | DÃ©clenchÃ© **uniquement** si policy active             |
| DEV peut Ãªtre plus strict que PROD  | Champ `environment` dans vigie_policy_table           |
| Tests activables dynamiquement      | Table vigie_policy_test avec champ `enabled`          |
| Compute traÃ§able                    | Champs `compute_engine` + `compute_cost` dans rÃ©sultats |
| Aucune modification pipeline        | La policy SQL contrÃ´le tout dynamiquement             |

---

## ðŸ“Š Tables SQL

| Table                        | RÃ´le                                 |
|------------------------------|--------------------------------------|
| `dbo.vigie_ctrl`             | MÃ©triques run-level (volume, SLA, alertes) |
| `dbo.vigie_policy_table`     | Policy de gouvernance par dataset     |
| `dbo.vigie_policy_test`      | Tests activÃ©s par type et frÃ©quence   |
| `dbo.vigie_integrity_result` | RÃ©sultats dÃ©taillÃ©s d'intÃ©gritÃ©       |
| `dbo.ctrl_file_index`        | Index des fichiers ingÃ©rÃ©s (re-runs)  |
| `dbo.sla_profile`            | Profil SLA par dataset (feature future) |
| `dbo.sla_profile_execution_type` | Profil SLA par type d'exÃ©cution (actif) |
| `dbo.synapse_rowcount_cache`     | Cache row count Synapse (table tampon)  |

### ðŸ‘ï¸ `vigie_ctrl` â€” Table principale (run-level metrics)

Un enregistrement par run d'extraction. Contient toutes les mÃ©triques de volume, SLA, coÃ»ts et alertes.

**IdentitÃ© du run :**

| Colonne | Type | RÃ´le |
|---|---|---|
| `ctrl_id` | varchar(200) | **PK** â€” identifiant unique du run |
| `dataset` | varchar(50) | Nom du dataset |
| `periodicity` | varchar(10) | FrÃ©quence (D/W/M/Q) |
| `extraction_date` | date | Date d'extraction |
| `expected_rows` | int | Lignes attendues |
| `source_system` | varchar(50) | SystÃ¨me source |
| `created_ts` | datetime2(7) | Timestamp de crÃ©ation |
| `pipeline_run_id` | varchar(100) | ID du pipeline ADF |
| `adf_pipeline_name` | varchar(100) | Nom du pipeline ADF |
| `adf_trigger_name` | varchar(100) | Nom du trigger ADF |
| `start_ts` / `end_ts` | datetime2(7) | DÃ©but / fin du run |
| `duration_sec` | int | DurÃ©e totale (sec) |
| `status` | varchar(20) | Statut du run |
| `status_global` | varchar(20) | Statut agrÃ©gÃ© global |
| `inserted_ts` | datetime2(7) | Auto : date d'insertion (UTC) |

**Volume (Bronze / Parquet) :**

| Colonne | Type | RÃ´le |
|---|---|---|
| `bronze_rows` / `parquet_rows` | int | Row count par couche |
| `bronze_delta` / `parquet_delta` | int | Delta vs expected |
| `bronze_status` / `parquet_status` | varchar | OK / LOW / ANOMALY |
| `volume_status` | varchar(20) | Statut volume agrÃ©gÃ© |
| `row_count_adf_ingestion_copie_parquet` | int | Rows copiÃ©es par ADF vers parquet |

**SLA par moteur :**

| PrÃ©fixe | Colonnes | Description |
|---|---|---|
| `sla_*` | `sla_sec`, `sla_expected_sec`, `sla_threshold_sec`, `sla_status`, `sla_reason`, `sla_bucket` | SLA global |
| `oeil_sla_*` | `oeil_sla_sec`, `oeil_sla_expected_sec`, `oeil_sla_threshold_sec`, `oeil_sla_status`, `oeil_sla_reason` | SLA L'Å’IL |
| `adf_sla_*` | `adf_sla_sec`, `adf_sla_expected_sec`, `adf_sla_threshold_sec`, `adf_sla_status`, `adf_sla_reason` | SLA ADF |
| `synapse_sla_*` | `synapse_sla_sec`, `synapse_sla_expected_sec`, `synapse_sla_threshold_sec`, `synapse_sla_status`, `synapse_sla_reason` | SLA Synapse |

**Alertes & CoÃ»ts :**

| Colonne | Type | RÃ´le |
|---|---|---|
| `alert_flag` | bit | Alerte dÃ©clenchÃ©e ? |
| `alert_level` | varchar(20) | NO_ALERT / INFO / WARNING / CRITICAL |
| `alert_reason` | varchar(100) | Raison de l'alerte |
| `alert_ts` | datetime2(7) | Timestamp de l'alerte |
| `synapse_cost_estimated_cad` | decimal(10,6) | CoÃ»t estimÃ© Synapse (CAD) |
| `synapse_cost_rate_cad_per_min` | decimal(10,6) | Taux $/min Synapse |

**IntÃ©gritÃ© payload :**

| Colonne | Type | RÃ´le |
|---|---|---|
| `payload_canonical` | varchar(500) | Forme canonique du payload |
| `payload_hash_sha256` | char(64) | Hash SHA-256 dÃ©terministique |
| `payload_hash_version` | tinyint | Version de l'algorithme de hash |
| `payload_hash_match` | bit | Hash correspond ? |

> **Index** : `IX_vigie_ctrl_dataset_date` sur (`dataset`, `periodicity`, `extraction_date`) pour les lookups rapides.

### ðŸ“‚ `ctrl_file_index` â€” Index des fichiers ingÃ©rÃ©s

InsÃ©rÃ©e lors de l'upload rÃ©ussi d'un fichier sur le lake bronze. Essentielle pour les re-runs.

| Colonne | Type | RÃ´le |
|---|---|---|
| `ctrl_id` | nvarchar(200) | **PK** â€” identifiant unique du contrÃ´le |
| `dataset` | nvarchar(200) | Nom du dataset |
| `ctrl_path` | nvarchar(1024) | Chemin logique complet du fichier |
| `processed_flag` | bit | Re-run : `0` = Ã  traiter, `1` = dÃ©jÃ  traitÃ© |
| `processed_ts` | datetime2(3) | Timestamp du traitement |
| `created_ts` | datetime2(3) | Auto : date de crÃ©ation (UTC) |
| `ctrl_path_hash` | binary(32) | **Computed + Unique Index** â€” SHA-256 du chemin (dÃ©doublonnage) |

### ðŸ“ˆ `sla_profile` â€” Profil SLA par dataset (feature future)

Calcul de SLA de base par dataset : `SLA = base_overhead_sec + (rows / 1000) Ã— sec_per_1k_rows` avec marge de tolÃ©rance.

| Colonne | Type | RÃ´le |
|---|---|---|
| `dataset` | nvarchar(200) | **PK** â€” un profil SLA par dataset |
| `base_overhead_sec` | int | Overhead fixe de base (secondes) |
| `sec_per_1k_rows` | int | CoÃ»t variable par tranche de 1K lignes |
| `tolerance_pct` | decimal(5,2) | TolÃ©rance en % avant alerte SLA |
| `active_flag` | bit | Actif/inactif (default `1`) |
| `created_ts` | datetime2(3) | Auto : date de crÃ©ation (UTC) |

### âš¡ `sla_profile_execution_type` â€” Profil SLA par type d'exÃ©cution (actif)

Version en production â€” profils SLA par type d'exÃ©cution (ADF / SYNAPSE / OEIL).

| Colonne | Type | RÃ´le |
|---|---|---|
| `execution_type` | varchar(30) | **PK** â€” type d'exÃ©cution |
| `base_overhead_sec` | int | Overhead fixe (secondes) |
| `sec_per_1k_rows` | int (nullable) | CoÃ»t variable par 1K lignes |
| `tolerance_pct` | decimal(5,2) | TolÃ©rance en % |
| `active_flag` | bit | Actif (default `1`) |
| `created_ts` | datetime2(3) | Date de crÃ©ation (UTC) |

**DonnÃ©es de base :**

| execution_type | overhead | /1K rows | tolÃ©rance |
|---|---|---|---|
| **ADF** | 30s | 5s | 25% |
| **OEIL** | 360s (6 min) | â€” | 22% |
| **SYNAPSE** | 120s (2 min) | â€” | 30% |

### ðŸ—„ï¸ `synapse_rowcount_cache` â€” Cache row count Synapse

Table tampon pour Ã©viter les requÃªtes Synapse coÃ»teuses et rÃ©pÃ©titives. Stocke les row counts par dataset/periodicitÃ©/date/layer. PremiÃ¨re Ã©bauche fonctionnelle â€” la logique d'agrÃ©gation complÃ¨te reste Ã  programmer.

| Colonne | Type | RÃ´le |
|---|---|---|
| `dataset` | varchar(50) | **PK (1/4)** â€” nom du dataset |
| `periodicity` | varchar(10) | **PK (2/4)** â€” frÃ©quence (D/W/M/Q) |
| `extraction_date` | date | **PK (3/4)** â€” date d'extraction |
| `layer` | varchar(10) | **PK (4/4)** â€” couche (bronze/silver/gold) |
| `row_count` | int | Nombre de lignes comptÃ©es |
| `computed_ts` | datetime2(7) | Auto : timestamp du calcul (UTC) |

> **Design** : PK composite Ã  4 colonnes = un row count unique par combinaison dataset + periodicitÃ© + date + layer. Pas de surrogate key â€” la clÃ© naturelle suffit pour le cache.

---

## ðŸ”® Roadmap

- [ ] Orchestration conditionnelle Synapse via policy SQL
- [ ] Export policy â†’ JSON dans le lac
- [ ] Dashboard Power BI connectÃ© Ã  vigie_ctrl
- [ ] Notification Teams / Email sur CRITICAL
- [ ] Support multi-environnement (DEV / UAT / PROD)
- [ ] IntÃ©gration Log Analytics KQL pour audit trail

---

## ðŸ“œ License

Projet interne â€” L'Å’IL Framework Â© 2026
