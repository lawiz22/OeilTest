# âš¡ Design Decisions

L'Å’IL a Ã©tÃ© conÃ§u avec des contraintes spÃ©cifiques de coÃ»t, traÃ§abilitÃ© et simplicitÃ© opÃ©rationnelle.

## 1. Pourquoi SQL comme source de vÃ©ritÃ© ?

**DÃ©cision** : Utiliser Azure SQL (table `vigie_ctrl`) plutÃ´t qu'un Data Lake ou Cosmos DB.

**Rationale** :
1.  **Relationnel** : Les mÃ©tadonnÃ©es sont fortement structurÃ©es (run -> dataset -> metrics).
2.  **T-SQL** : Langage universel pour les Data Engineers.
3.  **IntÃ©gration Power BI** : Direct Query natif et performant.
4.  **Transactionnel** : `SP_Set_Start` et `SP_Set_End` garantissent l'atomicitÃ© des mises Ã  jour d'Ã©tat.

## 2. Gestion des CoÃ»ts Synapse

**DÃ©cision** : Synapse Serverless est utilisÃ© **uniquement** si la policy du dataset l'autorise (`synapse_allowed = 1`).

**Rationale** :
*   Synapse facture au volume scannÃ© (TB).
*   ADF peut faire des validations simples (row count, file size) gratuitement.
*   On rÃ©serve Synapse pour les validations complexes (checksum contenu, distribution statistique) qui nÃ©cessitent de lire tout le fichier.

### Comparatif des approches de validation (coÃ»t / complexitÃ© / latence)

Ce comparatif sert de rÃ©fÃ©rence stratÃ©gique pour choisir la bonne mÃ©thode de validation selon le contexte dataset/environnement.

| MÃ©thode | CoÃ»t | ComplexitÃ© | Latence | Usage recommandÃ© |
|---|---|---|---|---|
| SQL External Table | ğŸ’² faible | simple | rapide | Tests simples |
| Synapse Serverless | ğŸ’² variable | moyen | moyen | Validations ciblÃ©es |
| Synapse Dedicated | ğŸ’²ğŸ’²ğŸ’² | Ã©levÃ© | rapide | Workloads critiques |
| Spark Notebook | ğŸ’²ğŸ’² | plus lourd | plus lent | Analytics avancÃ© |

### Architecture mature (pattern cible)

Dans une grande organisation, le pattern cible recommandÃ© est le suivant :

| Type dâ€™opÃ©ration | Moteur |
|---|---|
| Row count | SQL |
| Min / Max | SQL |
| Null count | SQL |
| Simple delta | SQL |
| Checksum massif | Synapse |
| AgrÃ©gation lourde multi-partition | Synapse |
| Traitement distribuÃ© complexe | Spark |

## 3. Double SLA (Volume-Based vs Fixed)

**DÃ©cision** : Distinguer le calcul de SLA selon le moteur.

**Rationale** :
*   **ADF** : Le temps de copie est linÃ©aire par rapport au volume. Un fichier de 10GB prendra 10x plus de temps qu'1GB.
    *   *Formule* : `Overhead + (Volume * CostFactor)`
*   **Synapse/OEIL** : Le temps est dominÃ© par le "cold start" et l'overhead rÃ©seau.
    *   *Formule* : `Fixed Overhead`

## 4. Fichiers CTRL Immuables

**DÃ©cision** : Chaque run gÃ©nÃ¨re un JSON `CTRL` dans le lac.

**Rationale** :
*   **Audit Trail** : MÃªme si la DB SQL est purgÃ©e ou corrompue, l'historique des runs est prÃ©servÃ© dans le lac.
*   **Non-RÃ©pudiation** : Le hash SHA-256 du payload garantit que le rÃ©sultat du contrÃ´le n'a pas Ã©tÃ© modifiÃ©.
*   **DÃ©couplage** : Les consommateurs en aval peuvent lire le fichier `.done` et le `CTRL` associÃ© sans toucher Ã  la DB SQL.

## 5. Philosophie : ObservabilitÃ© vs Blocage

> **"L'Å’IL ne doit pas Ãªtre un moteur qui bloque, mais un moteur qui rÃ©vÃ¨le."**

Le but fondamental du framework n'est pas d'arrÃªter les pipelines au moindre Ã©cart (ce qui paralyse le business), mais de fournir une visibilitÃ© totale sur la qualitÃ©.

Il doit :
1.  **DÃ©tecter** l'anomalie.
2.  **Classifier** sa sÃ©vÃ©ritÃ©.
3.  **Alerter** les bonnes personnes.
4.  **Mesurer** l'impact et la tendance.
5.  **Ne pas interfÃ©rer** avec le flux de donnÃ©es critique, sauf en cas de corruption avÃ©rÃ©e.

## 6. StratÃ©gie Environnementale (DEV vs PROD)

Le comportement du framework doit s'adapter au cycle de vie du dÃ©veloppement.

### En DEV : "Fail Fast, Watch Closely"
*   **Validation stricte** : On veut casser le pipeline si la donnÃ©e n'est pas parfaite.
*   **FrÃ©quence Ã©levÃ©e** : Tests systÃ©matiques Ã  chaque run.
*   **Checksum frÃ©quent** : Validation de contenu agressive pour dÃ©tecter les rÃ©gressions de code.
*   **Monitoring agressif** : Le dÃ©veloppeur doit voir immÃ©diatement l'impact de ses changements.
*   **Observation des coÃ»ts** : Mesure prÃ©cise de l'impact financier des nouvelles transformations.

### En PROD : "Business Continuity & Efficiency"
*   **Tests essentiels seulement** : On ne valide que ce qui protÃ¨ge le business.
*   **FrÃ©quence optimisÃ©e** : Checksums lourds uniquement hebdomadaires ou mensuels.
*   **Compute contrÃ´lÃ©** : Usage de Synapse restreint pour maÃ®triser la facture cloud.
*   **Pas dâ€™effet sur la performance mÃ©tier** : Les contrÃ´les ne doivent pas retarder la mise Ã  disposition des donnÃ©es.
*   **Policy adaptÃ©e** : Les seuils sont ajustÃ©s selon le comportement rÃ©el observÃ© ("drift" naturel acceptÃ© si non critique).

## 7. ChaÃ®ne dÃ©cisionnelle & sÃ©mantique des statuts

ChaÃ®ne de traitement cible :

`Dataset â†’ Policy â†’ Tests autorisÃ©s â†’ Moteur choisi â†’ RÃ©sultat â†’ SLA â†’ Alert`

Clarification des statuts :

- `status` = statut opÃ©rationnel du run
- `status_global` = statut consolidÃ©
- `alert_level` = sÃ©vÃ©ritÃ© finale

## 8. Risques connus

- DÃ©pendance Ã  la qualitÃ© du CTRL source.
- Risque de dÃ©rive si la policy est mal configurÃ©e.
- CoÃ»t Synapse sous-estimÃ© si exÃ©cution multi-partitions.

## 9. FAQ stratÃ©gique â€” â€œPourquoi ne pas utiliser un module Azure existant ?â€

### RÃ©ponse courte

Il nâ€™existe pas, Ã  ce jour, de service unique qui couvre exactement le pÃ©rimÃ¨tre de Lâ€™Å’IL.

Azure propose des briques puissantes (monitoring, catalogage, observabilitÃ© technique), mais pas un framework run-level qui combine simultanÃ©ment:

- Contrat mÃ©tier (`CTRL`) et validation dÃ©clarÃ©e vs observÃ©e.
- SLA multi-moteur (`ADF` + `Synapse` + orchestration Å’IL).
- Policy dynamique SQL-first appliquÃ©e Ã  lâ€™exÃ©cution.
- Snapshot JSON immuable et hash de non-rÃ©pudiation.
- Estimation de coÃ»t Synapse par contrÃ´le.
- Bucket mÃ©tier (`FAST` / `SLOW` / `VERY_SLOW`).
- Alerting contextualisÃ© mÃ©tier.

ğŸ‘‰ Lâ€™Å’IL est un framework dâ€™orchestration qualitÃ© orientÃ© exÃ©cution, pas un simple outil de monitoring.

### Azure Purview â€” DiffÃ©rence stratÃ©gique

**Purview = gouvernance et catalogage global.**

Purview couvre trÃ¨s bien:

- Data catalog
- Lineage
- Discovery
- Classification (PII, etc.)
- Profiling qualitÃ© statique

Purview ne cible pas nativement:

- Comparaison `CTRL` vs rÃ©alitÃ© observÃ©e run par run
- SLA ingestion multi-moteur opÃ©rationnel
- Rowcount contractuel au contrÃ´le
- Alerting orientÃ© exÃ©cution pipeline
- Estimation coÃ»t Synapse par run
- Policy dynamique appliquÃ©e Ã  chaud Ã  lâ€™exÃ©cution

ğŸ‘‰ Purview = gouvernance transverse.
ğŸ‘‰ Lâ€™Å’IL = contrÃ´le opÃ©rationnel run-level.

### Dynatrace â€” DiffÃ©rence stratÃ©gique

**Dynatrace = APM / performance systÃ¨me applicative.**

Dynatrace couvre:

- Monitoring infrastructure
- Monitoring services
- Traces applicatives
- CPU / mÃ©moire / latence

Dynatrace ne couvre pas nativement:

- Validation de volume mÃ©tier
- ContrÃ´le dâ€™intÃ©gritÃ© data contractuel
- Comparaison `expected_rows` vs `actual_rows`
- SLA orientÃ© logique mÃ©tier data
- ContrÃ´les `MIN/MAX`, checksum ou rÃ¨gles data lake

ğŸ‘‰ Dynatrace = santÃ© systÃ¨me.
ğŸ‘‰ Lâ€™Å’IL = qualitÃ© et conformitÃ© data.

### Azure natif (Monitor + Alerts) â€” Positionnement

Azure Monitor / Log Analytics:

- Donne des mÃ©triques techniques robustes
- Ne porte pas, seul, la sÃ©mantique mÃ©tier dataset
- Ne gÃ¨re pas nativement un contrat `expected_rows`
- Ne pilote pas, seul, une policy dynamique par dataset

ğŸ‘‰ Azure fournit les briques.
ğŸ‘‰ Lâ€™Å’IL orchestre, contextualise et consolide ces briques en dÃ©cision mÃ©tier actionnable.

## 10. Checksum (Hash) â€” stratÃ©gie (en cours)

Cette section formalise la trajectoire checksum pour Lâ€™Å’IL. Le sujet est en cours dâ€™industrialisation, avec montÃ©e progressive de la profondeur de contrÃ´le.

### Niveaux possibles

#### Niveau 1 â€” Hash clÃ© unique

Exemple:

`HASH(client_id)`

Usage:

- DÃ©tection dâ€™ajout/suppression de clÃ©s
- ContrÃ´le lÃ©ger Ã  faible coÃ»t

#### Niveau 2 â€” Hash colonnes critiques

Exemple:

`HASH(client_id + statut + pays)`

Usage:

- Validation mÃ©tier ciblÃ©e
- DÃ©tection de dÃ©rives sur attributs sensibles

#### Niveau 3 â€” Hash ligne complÃ¨te

Exemple:

`HASH(CONCAT_WS('|', col1, col2, col3, col4))`

Usage:

- IntÃ©gritÃ© forte au niveau enregistrement
- DÃ©tection dâ€™altÃ©rations non visibles par rowcount/min-max

#### Niveau 4 â€” Hash dataset complet ordonnÃ©

Exemple:

`HASH_AGG(row_hash ORDER BY key)`

Usage:

- Garantie forte dâ€™identitÃ© dataset
- Validation globale de non-altÃ©ration entre deux Ã©tats

### Cas pratiques pour Lâ€™Å’IL

#### En DEV

- Checksum ligne complÃ¨te
- FrÃ©quence `DAILY`
- Synapse autorisÃ©

#### En PROD

- Checksum clÃ© unique `DAILY`
- Checksum ligne complÃ¨te `WEEKLY`
- Activation pilotÃ©e par policy

### Points critiques (implÃ©mentation)

#### 1) Normalisation obligatoire

Avant hash, appliquer systÃ©matiquement:

- `NULL` â†’ chaÃ®ne vide
- `TRIM`
- format date ISO
- format dÃ©cimal stable
- `UPPER()` sur les textes mÃ©tier si nÃ©cessaire

Sans normalisation stricte, risque Ã©levÃ© de faux positifs.

#### 2) Ordre dÃ©terministe

Toujours imposer:

`ORDER BY primary_key`

Sans ordre stable, le hash agrÃ©gÃ© peut varier Ã  contenu identique.

#### 3) Types flottants

Les `FLOAT` peuvent varier lÃ©gÃ¨rement selon moteur/conversion.

Toujours caster en chaÃ®ne formatÃ©e fixe avant calcul du hash.

### Positionnement policy dans Lâ€™Å’IL

Pattern recommandÃ©: 3 niveaux de policy sÃ©lectionnables par dataset/environnement.

| Level | Type | FrÃ©quence |
|---|---|---|
| `LIGHT` | Key hash | `DAILY` |
| `STANDARD` | Critical columns hash | `DAILY` |
| `STRICT` | Full row hash | `WEEKLY` |

La policy choisit dynamiquement le niveau selon criticitÃ©, coÃ»t et frÃ©quence cible.

### Comparaison stratÃ©gique des contrÃ´les

| ContrÃ´le | DÃ©tecte ajout | DÃ©tecte modification | DÃ©tecte corruption |
|---|---|---|---|
| Rowcount | âœ… | âŒ | âŒ |
| Min/Max | âŒ | partiel | âŒ |
| Checksum clÃ© | âœ… | âŒ | âœ… |
| Checksum ligne | âœ… | âœ… | âœ… |
