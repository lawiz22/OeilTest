# ðŸŽ¬ Demo Run â€” End-to-End

Documentation pas Ã  pas dâ€™un run de dÃ©monstration Lâ€™Å’IL, avec screenshots.

## Ã‰tape 1 â€” Run extraction simulÃ© (source externe type DataStage via Control-M)

### Contexte

- ExÃ©cution de `python/runners/run_extractions.py` avec `config/run_extractions.json`.
- Simulation d'une extraction amont externe (ex: DataStage orchestrÃ© par Control-M).
- Datasets: `transactions` et `clients`.
- FenÃªtre de dÃ©monstration: du `2026-03-01` au `2026-03-02` (pÃ©riodicitÃ© `Q`).

### InterprÃ©tation mÃ©tier

Cette Ã©tape reprÃ©sente lâ€™**Å“il gauche** (la source amont et le contrat de livraison). On valide ici que l'extraction simulÃ©e produit correctement les jeux attendus avant le transfert vers le lake.

### Lecture du log (screenshot)

- `[OK] SQLite schema ensured` confirme que l'environnement local de dÃ©mo est prÃªt.
- Chaque ligne `transactions|...` / `clients|...` correspond Ã  un `ctrl_id` candidat pour l'orchestration ADF.
- `actual = expected` indique une gÃ©nÃ©ration cohÃ©rente (cas de base sans anomalie injectÃ©e).
- `min` / `max` donnent les bornes des valeurs gÃ©nÃ©rÃ©es pour le dataset.

### Screenshot

> Fichier: `docs/screenshots/demo_v2_step1_run_extractions_external_simulation.png`

![Ã‰tape 1 â€” Run extractions simulÃ© (source externe)](../screenshots/demo_v2_step1_run_extractions_external_simulation.png)

---

## Ã‰tape 2 â€” Push simulÃ© vers le lake (AzCopy)

### Contexte

- ExÃ©cution de `azcopy_uploader.py`.
- Cette Ã©tape simule la livraison des fichiers extraits vers ADLS Bronze depuis un systÃ¨me amont.
- RÃ©sultat attendu: job AzCopy terminÃ© avec transferts complÃ©tÃ©s et aucun Ã©chec.

### InterprÃ©tation mÃ©tier

Cette Ã©tape valide le passage entre le systÃ¨me d'extraction amont et le stockage technique Azure:

- les fichiers sont effectivement dÃ©posÃ©s en Bronze,
- lâ€™orchestration ADF peut dÃ©marrer sur des entrÃ©es prÃ©sentes,
- la qualitÃ© mÃ©tier sera Ã©valuÃ©e plus tard dans `PL_Oeil_Guardian` puis `PL_Oeil_Core`.

### Lecture du log (screenshot)

- `Final Job Status: Completed` = transfert rÃ©ussi
- `Number of File Transfers Completed` = nombre de fichiers rÃ©ellement copiÃ©s
- `Failed: 0` / `Skipped: 0` = aucun Ã©chec et aucun fichier ignorÃ©

### Screenshot

> Fichier: `docs/screenshots/demo_v2_step2_azcopy_push_to_lake.png`

![Ã‰tape 2 â€” Push AzCopy vers ADLS Bronze](../screenshots/demo_v2_step2_azcopy_push_to_lake.png)

---

## Ã‰tape 2b â€” CrÃ©ation de la ligne `ctrl_file_index` aprÃ¨s AzCopy

### Contexte

- AprÃ¨s lâ€™upload AzCopy, une entrÃ©e de contrÃ´le est enregistrÃ©e cÃ´tÃ© SQL.
- La table `dbo.ctrl_file_index` trace le `ctrl_id`, le `ctrl_path` et le statut de traitement.

### InterprÃ©tation mÃ©tier

Cette Ã©tape matÃ©rialise le lien entre le dÃ©pÃ´t physique des fichiers et lâ€™orchestration aval :

- lâ€™Ã©vÃ©nement est indexÃ© de faÃ§on idempotente,
- le run devient traÃ§able avant mÃªme les calculs de qualitÃ©/SLA,
- le flag `processed_flag` permettra de confirmer la consommation du contrÃ´le en fin de chaÃ®ne.

### Screenshot

> Fichier: `docs/screenshots/demo_step2b_ctrl_file_index_created_after_azcopy.png`

![Ã‰tape 2b â€” Ligne ctrl_file_index crÃ©Ã©e aprÃ¨s AzCopy](../screenshots/demo_step2b_ctrl_file_index_created_after_azcopy.png)

---

## Ã‰tape 3 â€” DÃ©tection Blob et dÃ©marrage des pipelines dâ€™ingestion principaux

### Contexte

- Le trigger Blob dÃ©tecte l'arrivÃ©e des nouveaux fichiers Bronze.
- `PL_Bronze_Event_Master` dÃ©marre automatiquement.
- L'orchestration d'ingestion lance ensuite `PL_Bronze_To_Standardized_Parquet`.

### InterprÃ©tation mÃ©tier

Cette Ã©tape confirme que la chaÃ®ne dâ€™ingestion ADF est bien **event-driven**:

- dÃ©tection automatique des dÃ©pÃ´ts Bronze,
- dÃ©marrage du pipeline principal dâ€™ingestion,
- enchaÃ®nement vers la standardisation sans intervention manuelle.

### Lecture du screenshot

- `PL_Bronze_Event_Master` apparaÃ®t comme point dâ€™entrÃ©e dÃ©clenchÃ© par le Blob event.
- Le run de `PL_Bronze_To_Standardized_Parquet` est visible dans la chaÃ®ne dâ€™ingestion.
- Les Ã©tats (`In progress` / `Succeeded`) confirment lâ€™exÃ©cution rÃ©elle au moment de la capture.

### Screenshot

> Fichier: `docs/screenshots/demo_v2_step3_blob_detect_master_ingestion_start.png`

![Ã‰tape 3 â€” Blob detect et dÃ©marrage ingestion principale](../screenshots/demo_v2_step3_blob_detect_master_ingestion_start.png)

---

## Ã‰tape 4 â€” DÃ©marrage `PL_Oeil_Guardian` et poke ADF Log Analytics

### Contexte

- `PL_Oeil_Guardian` dÃ©marre aprÃ¨s lâ€™ingestion Bronze â†’ Standardized.
- Le pipeline effectue un appel token (`WEB_Get_LogAnalytics_Token`) puis un poke KQL (`WEB_ADF_RowCount_Copie_Parquet`).
- Objectif: rÃ©cupÃ©rer les mÃ©triques du run Bronze exact via `p_pipeline_run_id`.

### InterprÃ©tation mÃ©tier

Cette Ã©tape valide la transition entre ingestion et contrÃ´le:

- Guardian commence lâ€™initialisation du run `vigie_ctrl`,
- la sonde Log Analytics confirme la disponibilitÃ© des mÃ©triques dâ€™activitÃ© ADF,
- ces mÃ©triques seront utilisÃ©es pour alimenter `adf_start_ts`, `adf_end_ts`, `adf_duration_sec` et le rowcount dâ€™ingestion.

### Screenshot

> Fichier: `docs/screenshots/demo_v2_step4_guardian_start_adf_log_probe.png`

![Ã‰tape 4 â€” PL_Oeil_Guardian dÃ©marre et poke ADF Log](../screenshots/demo_v2_step4_guardian_start_adf_log_probe.png)

---

## Ã‰tape 5 â€” DÃ©clenchement `PL_Oeil_Core` + `PL_Oeil_Quality_Engine` (avec cas dâ€™Ã©chec Guardian)

### Contexte

- On observe la sÃ©quence oÃ¹ Guardian enchaÃ®ne vers Core puis Quality.
- Dans ce run, un Guardian Ã©choue temporairement car les logs ADF ne sont pas encore disponibles au moment du poke.
- Le symptÃ´me est cohÃ©rent avec une latence de propagation Log Analytics.

### InterprÃ©tation mÃ©tier

Cette Ã©tape dÃ©montre un comportement opÃ©rationnel rÃ©aliste :

- la chaÃ®ne `Guardian -> Core -> Quality` est bien active,
- un Ã©chec ponctuel peut survenir si la tÃ©lÃ©mÃ©trie ADF arrive en retard,
- le paramÃ¨tre dâ€™attente (`Wait 60 sec`) peut Ãªtre augmentÃ© pour rÃ©duire ces faux Ã©checs transitoires.

### Screenshot

> Fichier: `docs/screenshots/demo_v2_step5_core_quality_trigger_guardian_log_delay.png`

![Ã‰tape 5 â€” Core/Quality dÃ©clenchÃ©s, Guardian en Ã©chec temporaire (logs ADF)](../screenshots/demo_v2_step5_core_quality_trigger_guardian_log_delay.png)

---

## Ã‰tape 6 â€” Reprise du run aprÃ¨s redÃ©pÃ´t `.done` (Guardian repasse et poursuit)

### Contexte

- Action corrective appliquÃ©e: suppression du fichier `.done`, puis redÃ©pÃ´t du `.done`.
- Le trigger relance Guardian sur le mÃªme contexte de partition.
- Cette fois, les logs ADF sont prÃªts et la chaÃ®ne poursuit normalement.

### InterprÃ©tation mÃ©tier

Cette Ã©tape valide la rÃ©silience du design event-driven:

- la reprise est possible sans intervention lourde,
- le redÃ©pÃ´t `.done` rejoue le contrÃ´le Guardian proprement,
- le pipeline refait ensuite ce quâ€™il devait faire (Core/Quality/SLA/alertes).

### Screenshot

> Fichier: `docs/screenshots/demo_v2_step6_guardian_rerun_after_done_redeposit.png`

![Ã‰tape 6 â€” Guardian relancÃ© aprÃ¨s redÃ©pÃ´t done, exÃ©cution reprise](../screenshots/demo_v2_step6_guardian_rerun_after_done_redeposit.png)

---

## Ã‰tape 7 â€” Cataloge `test_type` (dÃ©finition des tests)

### Contexte

- Consultation de `dbo.vigie_policy_test_type`.
- VÃ©rification du catalogue de tests disponibles.

### InterprÃ©tation mÃ©tier

Cette Ã©tape dÃ©finit **la nature** des tests exÃ©cutables :

- `test_code` normalise le type de contrÃ´le (`ROW_COUNT`, `MIN_MAX`, ...),
- `requires_synapse` indique les tests nÃ©cessitant Synapse,
- la jointure avec `vigie_policy_test` dÃ©termine le plan dâ€™exÃ©cution final.

### Screenshot

> Fichier: `docs/screenshots/demo_step7_policy_test_type_catalog.png`

![Ã‰tape 7 â€” Catalogue test_type](../screenshots/demo_step7_policy_test_type_catalog.png)

---

## Ã‰tape 8 â€” RÃ©sultats dâ€™intÃ©gritÃ© (`vigie_integrity_result`)

### Contexte

- ExÃ©cution effective des tests qualitÃ© via `PL_Oeil_Quality_Engine`.
- Persistance des rÃ©sultats techniques dans `dbo.vigie_integrity_result`.

### InterprÃ©tation mÃ©tier

Cette Ã©tape matÃ©rialise le rÃ©sultat du run qualitÃ© :

- une ligne par test exÃ©cutÃ© (`ROW_COUNT`, `MIN_MAX`),
- statut de test (`PASS`/`FAIL`) visible immÃ©diatement,
- traces numÃ©riques (`min_value`, `max_value`, `expected_value`, `delta_value`) exploitables pour audit.

Note importante : pour `ROW_COUNT`, la valeur de comptage est stockÃ©e dans `min_value` par convention technique.

### Lecture du screenshot

- Plusieurs `ctrl_id` de la dÃ©mo sont prÃ©sents sur la fenÃªtre dâ€™exÃ©cution.
- Les tests `ROW_COUNT` et `MIN_MAX` sont tous marquÃ©s `PASS`.
- `delta_value = 0` confirme l'alignement Bronze vs Parquet sur ces runs.

### Screenshot

> Fichier: `docs/screenshots/demo_step8_integrity_results_pass_rowcount_minmax.png`

![Ã‰tape 8 â€” RÃ©sultats integrity PASS (ROW_COUNT / MIN_MAX)](../screenshots/demo_step8_integrity_results_pass_rowcount_minmax.png)

---

## Ã‰tape 9 â€” Comparatif `vigie_ctrl` (avant / aprÃ¨s rejouage Guardian)

### Avant / AprÃ¨s rejouage Guardian (tableau vertical)

Cas analysÃ©: `transactions_2026-03-01_Q`.

| Champ | Avant rejouage Guardian | AprÃ¨s rejouage Guardian |
|---|---|---|
| `ctrl_id` | `transactions_2026-03-01_Q` | `transactions_2026-03-01_Q` |
| `status_global` | `IN_PROGRESS` | `COMPLETED` |
| `pipeline_run_id` | `NULL` | `6f33f2ce-a5d2-4f37-b392-aaafc4e9331f` |
| `adf_pipeline_name` | `NULL` | `PL_Oeil_Guardian` |
| `adf_trigger_name` | `NULL` | `TR_Oeil_Done` |
| `expected_rows` | `NULL` | `1176` |
| `bronze_rows` | `NULL` | `1176` |
| `parquet_rows` | `NULL` | `1176` |
| `row_count_adf_ingestion_copie_parquet` | `NULL` | `1176` |
| `start_ts` | `2026-02-19 13:26:37.9299689` | `2026-02-19 13:26:37.9299689` |
| `end_ts` | `NULL` | `2026-02-19 13:41:01.1972102` |
| `duration_sec` | `NULL` | `864` |
| `oeil_sla_status` | `NULL` | `FAIL` |
| `volume_status` | `NULL` | `OK` |
| `sla_bucket` | `NULL` | `VERY_SLOW` |
| `alert_flag` | `NULL` | `1` |
| `alert_level` | `NULL` | `CRITICAL` |
| `alert_reason` | `NULL` | `OEIL=FAIL | BUCKET=VERY_SLOW | VOLUME=OK | ADF=OK | SYNAPSE=OK` |
| `payload_hash_match` | `NULL` | `1` |

### Lecture mÃ©tier du comparatif

- Avant rejouage, la ligne reste bloquÃ©e en `IN_PROGRESS` (logs ADF pas encore prÃªts au moment du poke Guardian).
- AprÃ¨s suppression/redÃ©pÃ´t du `.done`, Guardian rejoue, complÃ¨te les mÃ©triques et dÃ©clenche correctement Core/Quality.
- La qualitÃ© volumÃ©trique reste `OK` sur ce `ctrl_id`, mais le SLA global bascule en `FAIL` Ã  cause dâ€™une exÃ©cution trop longue (`VERY_SLOW`).
- Le moteur dâ€™alerte reflÃ¨te bien ce scÃ©nario : `alert_level = CRITICAL` avec raison explicable.
- Les autres contrÃ´les (`clients_2026-03-01_Q`, `clients_2026-03-02_Q`, `transactions_2026-03-02_Q`) restent `COMPLETED` et `NO_ALERT`.

### Dictionnaire complet des champs (`vigie_ctrl`)

- `ctrl_id`: identifiant unique du contrÃ´le (dataset + date + pÃ©riodicitÃ©).
- `dataset`: nom du dataset contrÃ´lÃ©.
- `periodicity`: frÃ©quence de traitement (ex: `Q`, `H`, `D`).
- `extraction_date`: date mÃ©tier de la partition contrÃ´lÃ©e.
- `expected_rows`: volume attendu de rÃ©fÃ©rence.
- `source_system`: systÃ¨me source mÃ©tier.
- `created_ts`: timestamp de crÃ©ation initiale du contrÃ´le.
- `pipeline_run_id`: identifiant technique du run ADF.
- `adf_pipeline_name`: nom du pipeline ADF exÃ©cutÃ©.
- `adf_trigger_name`: nom du trigger ADF ayant dÃ©clenchÃ© le run.
- `start_ts`: horodatage de dÃ©but du cycle Å’IL.
- `status`: statut principal du run dans `vigie_ctrl`.
- `inserted_ts`: horodatage dâ€™insertion de la ligne en base.
- `bronze_rows`: nombre de lignes observÃ© cÃ´tÃ© Bronze.
- `bronze_delta`: Ã©cart Bronze vs attendu (`bronze_rows - expected_rows`).
- `bronze_status`: verdict Bronze (`OK` ou `MISMATCH`).
- `parquet_rows`: nombre de lignes observÃ© cÃ´tÃ© Parquet.
- `parquet_delta`: Ã©cart Parquet vs attendu (`parquet_rows - expected_rows`).
- `parquet_status`: verdict Parquet (`OK` ou `MISMATCH`).
- `status_global`: Ã©tat global du cycle (ex: `COMPLETED`).
- `sla_expected_sec`: objectif SLA nominal (en secondes).
- `sla_threshold_sec`: seuil maximal SLA acceptÃ© (en secondes).
- `end_ts`: horodatage de fin du cycle Å’IL.
- `duration_sec`: durÃ©e totale observÃ©e du cycle.
- `sla_sec`: valeur SLA globale mesurÃ©e.
- `sla_status`: verdict SLA global (`OK` / `BREACH`).
- `sla_reason`: raison de classification SLA globale.
- `volume_status`: verdict volumÃ©trique consolidÃ© (`OK` / `ANOMALY`).
- `sla_bucket`: classe de vitesse (`FAST`, `NORMAL`, ...).
- `row_count_adf_ingestion_copie_parquet`: volume comptÃ© pendant lâ€™ingestion ADF/copie Parquet.
- `adf_start_ts`: dÃ©but du segment ADF.
- `adf_end_ts`: fin du segment ADF.
- `adf_duration_sec`: durÃ©e du segment ADF.
- `adf_sla_status`: verdict SLA du segment ADF.
- `adf_sla_reason`: raison SLA du segment ADF.
- `synapse_start_ts`: dÃ©but du segment Synapse.
- `synapse_end_ts`: fin du segment Synapse.
- `synapse_duration_sec`: durÃ©e du segment Synapse.
- `oeil_sla_sec`: SLA mesurÃ© cÃ´tÃ© exÃ©cution Å’IL.
- `oeil_sla_expected_sec`: cible SLA cÃ´tÃ© Å’IL.
- `oeil_sla_threshold_sec`: seuil SLA cÃ´tÃ© Å’IL.
- `oeil_sla_status`: verdict SLA cÃ´tÃ© Å’IL.
- `oeil_sla_reason`: raison SLA cÃ´tÃ© Å’IL.
- `adf_sla_sec`: SLA mesurÃ© pour ADF.
- `adf_sla_expected_sec`: cible SLA ADF.
- `adf_sla_threshold_sec`: seuil SLA ADF.
- `synapse_sla_sec`: SLA mesurÃ© pour Synapse.
- `synapse_sla_expected_sec`: cible SLA Synapse.
- `synapse_sla_threshold_sec`: seuil SLA Synapse.
- `synapse_sla_status`: verdict SLA Synapse.
- `synapse_sla_reason`: raison SLA Synapse.
- `alert_flag`: indicateur binaire dâ€™alerte (`0`/`1`).
- `alert_reason`: raison textuelle de lâ€™alerte (rÃ¨gles consolidÃ©es).
- `alert_ts`: horodatage de levÃ©e dâ€™alerte.
- `synapse_cost_estimated_cad`: coÃ»t Synapse estimÃ© en CAD.
- `synapse_cost_rate_cad_per_min`: taux de coÃ»t appliquÃ© (CAD/min).
- `alert_level`: niveau final dâ€™alerte (`NO_ALERT`, `WARNING`, `CRITICAL`).
- `payload_canonical`: payload normalisÃ© servant Ã  la comparaison.
- `payload_hash_sha256`: hash SHA-256 du payload canonique.
- `payload_hash_version`: version de la mÃ©thode de hash.
- `payload_hash_match`: rÃ©sultat de comparaison de hash.
- `policy_dataset_id`: identifiant de la policy dataset appliquÃ©e.
- `policy_snapshot_json`: snapshot JSON de policy figÃ© au moment du run.

---

## Ã‰tape 10 â€” Tableau de bord Power BI (Executive Overview)

### Contexte

- Vue exÃ©cutive de synthÃ¨se pour lecture rapide du run.
- Focus : santÃ© globale, SLA, vitesse des runs, et signal dâ€™alertes.

### Lecture mÃ©tier du tableau exÃ©cutif

- `Runs Total = 3`: les trois partitions du scÃ©nario ont Ã©tÃ© traitÃ©es.
- `Runs FAST = 3`: performance globale dans la zone rapide.
- `ADF SLA OK = 3`, `SYNAPSE SLA OK = 3`, `OEIL SLA OK = 3`: conformitÃ© temps bout-en-bout.
- `Volume Issue Runs = 2`: deux runs ont Ã©tÃ© dÃ©tectÃ©s en dÃ©rive volumÃ©trique.
- `Volume Integrity Label = Volume Drift Detected`: le dashboard confirme le signal dâ€™anomalie volume dÃ©jÃ  visible dans `vigie_ctrl`.

### Message exÃ©cutif Ã  porter en dÃ©mo

Le pipeline est rapide et stable, mais il remonte correctement les Ã©carts volumÃ©triques mÃ©tier : la plateforme ne masque pas les anomalies sous un simple SLA Â« vert Â».

### Screenshot

> Fichier: `docs/screenshots/demo_step10_powerbi_executive_overview.png`

![Ã‰tape 10 â€” Power BI Executive Overview](../screenshots/demo_step10_powerbi_executive_overview.png)

---

## Ã‰tape 11 â€” Tableau de bord Power BI (Volume Watch)

### Contexte

- Vue dÃ©diÃ©e au suivi de la qualitÃ© volumÃ©trique.
- Sert de point dâ€™entrÃ©e pour les futurs drill-down par type de problÃ¨me.

### Lecture mÃ©tier

- Permet de suivre les anomalies de volume par run/dataset/pÃ©riode.
- PrÃ©pare les analyses dÃ©taillÃ©es (Ã©carts attendus vs observÃ©s, priorisation des incidents).
- ComplÃ¨te la vue exÃ©cutive avec un axe â€œproblÃ¨me dâ€™intÃ©gritÃ©â€ plus opÃ©rationnel.

### Screenshot

> Fichier: `docs/screenshots/demo_step11_powerbi_volume_watch.png`

![Ã‰tape 11 â€” Power BI Volume Watch](../screenshots/demo_step11_powerbi_volume_watch.png)

---

âœ… DÃ©mo end-to-end documentÃ©e (version actuelle)

- ChaÃ®ne couverte: extraction â†’ ingestion â†’ orchestration ADF â†’ quality engine â†’ consolidation `vigie_ctrl` â†’ visualisation Power BI.
- Ã‰volution prÃ©vue: drill-downs Power BI par catÃ©gorie de problÃ¨me (volume, SLA, source dâ€™alerte).

---

Ã‰tapes suivantes Ã  documenter au fil des screenshots (optionnel):

1. Drill-down Power BI par problÃ¨me (volume/SLA/source)
