# ðŸŽ¬ Demo Run â€” End-to-End

Documentation pas Ã  pas dâ€™un run de dÃ©monstration Lâ€™Å’IL, avec screenshots.

## Ã‰tape 1 â€” Extraction Python (3 jours, dataset `clients`, chaos 20%)

### Contexte

- ExÃ©cution de `python/runners/run_extractions.py`
- Dataset: `clients`
- FenÃªtre: 3 jours
- Bruit chaotique (variance): **20%**

### InterprÃ©tation mÃ©tier

Cette Ã©tape simule lâ€™**Å“il gauche** (source/contrat, ex: DataStage ou autre systÃ¨me amont) via les programmes Python.

Avec 20% de bruit, le rÃ©sultat source simulÃ© peut diverger de la premiÃ¨re ingestion attendue. Câ€™est volontaire pour dÃ©montrer la capacitÃ© de Lâ€™Å’IL Ã  dÃ©tecter et qualifier les Ã©carts.

### Lecture du log (screenshot)

- `actual` = volume rÃ©ellement gÃ©nÃ©rÃ© cÃ´tÃ© simulation source
- `expected` = volume de rÃ©fÃ©rence attendu
- `[WARN] VARIANCE` = Ã©cart volontaire injectÃ© (cas de test)
- `min` / `max` = bornes du jeu gÃ©nÃ©rÃ©

### Screenshot

> Fichier attendu: `docs/screenshots/demo_step1_extraction_clients_3jours_chaos20.png`

![Ã‰tape 1 â€” Extraction clients 3 jours chaos 20%](../screenshots/demo_step1_extraction_clients_3jours_chaos20.png)

---

## Ã‰tape 2 â€” Push simulÃ© DataStage/SFTP vers le lake (AzCopy)

### Contexte

- ExÃ©cution de `azcopy_uploader.py`
- Simulation du transfert amont (DataStage/SFTP) vers ADLS Bronze
- RÃ©sultat observÃ©: job `Completed`, transferts fichiers = OK

### InterprÃ©tation mÃ©tier

Cette Ã©tape simule lâ€™arrivÃ©e des artefacts source dans le lake.

- Le pipeline amont dÃ©pose les fichiers attendus en Bronze.
- Lâ€™upload rÃ©ussi confirme que le run peut passer Ã  lâ€™orchestration ADF.
- Ã€ ce stade, on valide la disponibilitÃ© des entrÃ©es, pas encore la qualitÃ© mÃ©tier.

### Lecture du log (screenshot)

- `Final Job Status: Completed` = transfert rÃ©ussi
- `Number of File Transfers Completed` = nombre de fichiers rÃ©ellement copiÃ©s
- `Failed: 0` / `Skipped: 0` = aucun Ã©chec et aucun fichier ignorÃ©

### Screenshot

> Fichier: `docs/screenshots/demo_step2_azcopy_push_lake.png`

![Ã‰tape 2 â€” Push AzCopy vers le lake](../screenshots/demo_step2_azcopy_push_lake.png)

---

## Ã‰tape 2b â€” CrÃ©ation de la ligne `ctrl_file_index` aprÃ¨s AzCopy

### Contexte

- AprÃ¨s lâ€™upload AzCopy, une entrÃ©e de contrÃ´le est enregistrÃ©e cÃ´tÃ© SQL.
- La table `dbo.ctrl_file_index` trace le `ctrl_id`, le `ctrl_path` et le statut de traitement.

### InterprÃ©tation mÃ©tier

Cette Ã©tape matÃ©rialise le lien entre le dÃ©pÃ´t physique des fichiers et lâ€™orchestration aval :

- lâ€™Ã©vÃ©nement est indexÃ© de faÃ§on idempotente,
- le run devient traÃ§able avant mÃªme les calculs de qualitÃ©/SLA,
- le flag `processed_flag` permettra de confirmer la consommation du contrÃ´le en fin de chaÃ®ne.

### Screenshot

> Fichier: `docs/screenshots/demo_step2b_ctrl_file_index_created_after_azcopy.png`

![Ã‰tape 2b â€” Ligne ctrl_file_index crÃ©Ã©e aprÃ¨s AzCopy](../screenshots/demo_step2b_ctrl_file_index_created_after_azcopy.png)

---

## Ã‰tape 3 â€” DÃ©tection Blob + orchestration `Master -> To_Standardized_Parquet`

### Contexte

- Le trigger Blob dÃ©tecte l'arrivÃ©e des fichiers Bronze.
- `PL_Bronze_Event_Master` est dÃ©clenchÃ© automatiquement.
- Ce pipeline dÃ©clenche `PL_Bronze_To_Standardized_Parquet` pour convertir en Parquet.

### InterprÃ©tation mÃ©tier

Cette Ã©tape valide la chaÃ®ne dâ€™orchestration event-driven ADF :

- dÃ©tection automatique de nouveaux fichiers,
- propagation du `ctrl_id` et des mÃ©tadonnÃ©es de partition,
- exÃ©cution du pipeline de standardisation sans intervention manuelle.

### Lecture du screenshot

- `PL_Bronze_Event_Master` : point dâ€™entrÃ©e dÃ©clenchÃ© par lâ€™Ã©vÃ©nement Blob.
- `PL_Bronze_To_Standardized_Parquet` : pipeline enfant de transformation.
- PrÃ©sence de runs `Succeeded` / `In progress` selon le moment de capture.

### Screenshot

> Fichier: `docs/screenshots/demo_step3_adf_blob_trigger_master_to_standardized.png`

![Ã‰tape 3 â€” Blob trigger et orchestration Master vers Standardized](../screenshots/demo_step3_adf_blob_trigger_master_to_standardized.png)

---

## Ã‰tape 4 â€” DÃ©pÃ´t du fichier `.done`

### Contexte

- AprÃ¨s la conversion Parquet, le pipeline dÃ©pose un fichier `{ctrl_id}.done`.
- Ce fichier signale la fin technique du traitement de la partition Bronze/Standardized.

### InterprÃ©tation mÃ©tier

Le `.done` joue le rÃ´le dâ€™accusÃ© de rÃ©ception machine-to-machine :

- confirme la complÃ©tion de la phase dâ€™ingestion/standardisation,
- autorise les Ã©tapes aval (`PL_Ctrl_To_Vigie`, qualitÃ©, SLA, alertes),
- facilite lâ€™orchestration idempotente par Ã©vÃ©nement.

### Screenshot

> Fichier: `docs/screenshots/demo_step4_done_file_deposited.png`

![Ã‰tape 4 â€” Fichier done dÃ©posÃ©](../screenshots/demo_step4_done_file_deposited.png)

---

## Ã‰tape 5 â€” Policy dataset (activation + autorisation Synapse)

### Contexte

- Consultation de la table `dbo.vigie_policy_dataset`.
- VÃ©rification des flags de gouvernance par dataset/environnement.

### InterprÃ©tation mÃ©tier

Cette Ã©tape confirme que la policy autorise lâ€™exÃ©cution qualitÃ© selon les rÃ¨gles attendues :

- `is_active` dÃ©termine si le dataset est pris en compte par lâ€™engine,
- `synapse_allowed` dÃ©cide si les contrÃ´les Synapse peuvent Ãªtre exÃ©cutÃ©s,
- `max_synapse_cost_usd` encadre le budget potentiel.

### Screenshot

> Fichier: `docs/screenshots/demo_step5_policy_dataset_synapse_allowed_active.png`

![Ã‰tape 5 â€” Policy dataset (active/synapse_allowed)](../screenshots/demo_step5_policy_dataset_synapse_allowed_active.png)

---

## Ã‰tape 6 â€” Policy test (tests activÃ©s Ã  exÃ©cuter)

### Contexte

- Consultation de `dbo.vigie_policy_test`.
- VÃ©rification des tests activÃ©s et de leur frÃ©quence/seuil.

### InterprÃ©tation mÃ©tier

Cette Ã©tape fixe **quoi** exÃ©cuter pour le run :

- `is_enabled` active/dÃ©sactive un test,
- `frequency` porte la logique dâ€™applicabilitÃ©,
- `threshold_value` et `column_name` paramÃ¨trent la rÃ¨gle.

### Screenshot

> Fichier: `docs/screenshots/demo_step6_policy_test_enabled_frequency_threshold.png`

![Ã‰tape 6 â€” Policy test (enabled/frequency/threshold)](../screenshots/demo_step6_policy_test_enabled_frequency_threshold.png)

---

## Ã‰tape 7 â€” Cataloge `test_type` (dÃ©finition des tests)

### Contexte

- Consultation de `dbo.vigie_policy_test_type`.
- VÃ©rification du catalogue de tests disponibles.

### InterprÃ©tation mÃ©tier

Cette Ã©tape dÃ©finit **la nature** des tests exÃ©cutables :

- `test_code` normalise le type de contrÃ´le (`ROW_COUNT`, `MIN_MAX`, ...),
- `requires_synapse` indique les tests nÃ©cessitant Synapse,
- la jointure avec `vigie_policy_test` dÃ©termine le plan dâ€™exÃ©cution final.

### Screenshot

> Fichier: `docs/screenshots/demo_step7_policy_test_type_catalog.png`

![Ã‰tape 7 â€” Catalogue test_type](../screenshots/demo_step7_policy_test_type_catalog.png)

---

## Ã‰tape 8 â€” RÃ©sultats dâ€™intÃ©gritÃ© persistÃ©s (`vigie_integrity_result`)

### Contexte

- ExÃ©cution effective des tests qualitÃ© via `PL_Oeil_Quality_Engine`.
- Persistance des rÃ©sultats techniques dans `dbo.vigie_integrity_result`.

### InterprÃ©tation mÃ©tier

Cette Ã©tape matÃ©rialise le â€œrÃ©sultat magiqueâ€ du run qualitÃ©:

- une ligne par test exÃ©cutÃ© (`ROW_COUNT`, `MIN_MAX`),
- statut de test (`PASS`/`FAIL`) visible immÃ©diatement,
- traces numÃ©riques (`min_value`, `max_value`, `expected_value`, `delta_value`) exploitables pour audit.

Note importante : pour `ROW_COUNT`, la valeur de comptage est stockÃ©e dans `min_value` par convention technique.

### Lecture du screenshot

- Plusieurs `ctrl_id` sur 3 jours (`2026-07-01` Ã  `2026-07-03`) sont prÃ©sents.
- Les tests `ROW_COUNT` et `MIN_MAX` sont tous marquÃ©s `PASS`.
- `delta_value = 0` confirme l'alignement Bronze vs Parquet sur ces runs.

### Screenshot

> Fichier: `docs/screenshots/demo_step8_integrity_results_pass_rowcount_minmax.png`

![Ã‰tape 8 â€” RÃ©sultats integrity PASS (ROW_COUNT / MIN_MAX)](../screenshots/demo_step8_integrity_results_pass_rowcount_minmax.png)

---

## Ã‰tape 9 â€” RÃ©sultat final consolidÃ© (`vigie_ctrl`)

### Tableau de synthÃ¨se (lisible mÃ©tier)

| ctrl_id | expected_rows | bronze_rows | parquet_rows | bronze_status | parquet_status | duration_sec | sla_status | volume_status | alert_level |
|---|---:|---:|---:|---|---|---:|---|---|---|
| clients_2026-07-01_Q | 1199 | 1199 | 1199 | OK | OK | 297 | OK | OK | NO_ALERT |
| clients_2026-07-02_Q | 741 | 996 | 996 | MISMATCH | MISMATCH | 309 | OK | ANOMALY | CRITICAL |
| clients_2026-07-03_Q | 1251 | 1570 | 1570 | MISMATCH | MISMATCH | 306 | OK | ANOMALY | CRITICAL |

### Explication mÃ©tier du rÃ©sultat final

- Le pipeline termine bien sur les 3 `ctrl_id` (`status_global = COMPLETED`).
- La performance est conforme (`sla_status = OK` sur les 3 runs).
- La qualitÃ© volumÃ©trique dÃ©tecte correctement 2 anomalies (`volume_status = ANOMALY`), malgrÃ© un SLA temps conforme.
- Le moteur dâ€™alerte est cohÃ©rent: `alert_level = CRITICAL` uniquement quand une anomalie volumÃ©trique est confirmÃ©e.
- Les coÃ»ts Synapse restent faibles et traÃ§ables (`synapse_cost_estimated_cad`).

### Dictionnaire complet des champs (`vigie_ctrl`)

- `ctrl_id`: identifiant unique du contrÃ´le (dataset + date + pÃ©riodicitÃ©).
- `dataset`: nom du dataset contrÃ´lÃ©.
- `periodicity`: frÃ©quence de traitement (ex: `Q`, `H`, `D`).
- `extraction_date`: date mÃ©tier de la partition contrÃ´lÃ©e.
- `expected_rows`: volume attendu de rÃ©fÃ©rence.
- `source_system`: systÃ¨me source mÃ©tier.
- `created_ts`: timestamp de crÃ©ation initiale du contrÃ´le.
- `pipeline_run_id`: identifiant technique du run ADF.
- `adf_pipeline_name`: nom du pipeline ADF exÃ©cutÃ©.
- `adf_trigger_name`: nom du trigger ADF ayant dÃ©clenchÃ© le run.
- `start_ts`: horodatage de dÃ©but du cycle Å’IL.
- `status`: statut principal du run dans `vigie_ctrl`.
- `inserted_ts`: horodatage dâ€™insertion de la ligne en base.
- `bronze_rows`: nombre de lignes observÃ© cÃ´tÃ© Bronze.
- `bronze_delta`: Ã©cart Bronze vs attendu (`bronze_rows - expected_rows`).
- `bronze_status`: verdict Bronze (`OK` ou `MISMATCH`).
- `parquet_rows`: nombre de lignes observÃ© cÃ´tÃ© Parquet.
- `parquet_delta`: Ã©cart Parquet vs attendu (`parquet_rows - expected_rows`).
- `parquet_status`: verdict Parquet (`OK` ou `MISMATCH`).
- `status_global`: Ã©tat global du cycle (ex: `COMPLETED`).
- `sla_expected_sec`: objectif SLA nominal (en secondes).
- `sla_threshold_sec`: seuil maximal SLA acceptÃ© (en secondes).
- `end_ts`: horodatage de fin du cycle Å’IL.
- `duration_sec`: durÃ©e totale observÃ©e du cycle.
- `sla_sec`: valeur SLA globale mesurÃ©e.
- `sla_status`: verdict SLA global (`OK` / `BREACH`).
- `sla_reason`: raison de classification SLA globale.
- `volume_status`: verdict volumÃ©trique consolidÃ© (`OK` / `ANOMALY`).
- `sla_bucket`: classe de vitesse (`FAST`, `NORMAL`, ...).
- `row_count_adf_ingestion_copie_parquet`: volume comptÃ© pendant lâ€™ingestion ADF/copie Parquet.
- `adf_start_ts`: dÃ©but du segment ADF.
- `adf_end_ts`: fin du segment ADF.
- `adf_duration_sec`: durÃ©e du segment ADF.
- `adf_sla_status`: verdict SLA du segment ADF.
- `adf_sla_reason`: raison SLA du segment ADF.
- `synapse_start_ts`: dÃ©but du segment Synapse.
- `synapse_end_ts`: fin du segment Synapse.
- `synapse_duration_sec`: durÃ©e du segment Synapse.
- `oeil_sla_sec`: SLA mesurÃ© cÃ´tÃ© exÃ©cution Å’IL.
- `oeil_sla_expected_sec`: cible SLA cÃ´tÃ© Å’IL.
- `oeil_sla_threshold_sec`: seuil SLA cÃ´tÃ© Å’IL.
- `oeil_sla_status`: verdict SLA cÃ´tÃ© Å’IL.
- `oeil_sla_reason`: raison SLA cÃ´tÃ© Å’IL.
- `adf_sla_sec`: SLA mesurÃ© pour ADF.
- `adf_sla_expected_sec`: cible SLA ADF.
- `adf_sla_threshold_sec`: seuil SLA ADF.
- `synapse_sla_sec`: SLA mesurÃ© pour Synapse.
- `synapse_sla_expected_sec`: cible SLA Synapse.
- `synapse_sla_threshold_sec`: seuil SLA Synapse.
- `synapse_sla_status`: verdict SLA Synapse.
- `synapse_sla_reason`: raison SLA Synapse.
- `alert_flag`: indicateur binaire dâ€™alerte (`0`/`1`).
- `alert_reason`: raison textuelle de lâ€™alerte (rÃ¨gles consolidÃ©es).
- `alert_ts`: horodatage de levÃ©e dâ€™alerte.
- `synapse_cost_estimated_cad`: coÃ»t Synapse estimÃ© en CAD.
- `synapse_cost_rate_cad_per_min`: taux de coÃ»t appliquÃ© (CAD/min).
- `alert_level`: niveau final dâ€™alerte (`NO_ALERT`, `WARNING`, `CRITICAL`).
- `payload_canonical`: payload normalisÃ© servant Ã  la comparaison.
- `payload_hash_sha256`: hash SHA-256 du payload canonique.
- `payload_hash_version`: version de la mÃ©thode de hash.
- `payload_hash_match`: rÃ©sultat de comparaison de hash.
- `policy_dataset_id`: identifiant de la policy dataset appliquÃ©e.
- `policy_snapshot_json`: snapshot JSON de policy figÃ© au moment du run.

---

## Ã‰tape 10 â€” Power BI (Executive Overview)

### Contexte

- Vue exÃ©cutive de synthÃ¨se pour lecture rapide du run.
- Focus: santÃ© globale, SLA, vitesse des runs, et signal dâ€™alertes.

### Lecture mÃ©tier du tableau exÃ©cutif

- `Runs Total = 3`: les trois partitions du scÃ©nario ont Ã©tÃ© traitÃ©es.
- `Runs FAST = 3`: performance globale dans la zone rapide.
- `ADF SLA OK = 3`, `SYNAPSE SLA OK = 3`, `OEIL SLA OK = 3`: conformitÃ© temps bout-en-bout.
- `Volume Issue Runs = 2`: deux runs ont Ã©tÃ© dÃ©tectÃ©s en dÃ©rive volumÃ©trique.
- `Volume Integrity Label = Volume Drift Detected`: le dashboard confirme le signal dâ€™anomalie volume dÃ©jÃ  visible dans `vigie_ctrl`.

### Message exÃ©cutif Ã  porter en dÃ©mo

Le pipeline est rapide et stable, mais il remonte correctement les Ã©carts volumÃ©triques mÃ©tier: la plateforme ne masque pas les anomalies sous un simple SLA â€œvertâ€.

### Screenshot

> Fichier: `docs/screenshots/demo_step10_powerbi_executive_overview.png`

![Ã‰tape 10 â€” Power BI Executive Overview](../screenshots/demo_step10_powerbi_executive_overview.png)

---

## Ã‰tape 11 â€” Power BI (Volume Watch)

### Contexte

- Vue dÃ©diÃ©e au suivi de la qualitÃ© volumÃ©trique.
- Sert de point dâ€™entrÃ©e pour les futurs drill-down par type de problÃ¨me.

### Lecture mÃ©tier

- Permet de suivre les anomalies de volume par run/dataset/pÃ©riode.
- PrÃ©pare les analyses dÃ©taillÃ©es (Ã©carts attendus vs observÃ©s, priorisation des incidents).
- ComplÃ¨te la vue exÃ©cutive avec un axe â€œproblÃ¨me dâ€™intÃ©gritÃ©â€ plus opÃ©rationnel.

### Screenshot

> Fichier: `docs/screenshots/demo_step11_powerbi_volume_watch.png`

![Ã‰tape 11 â€” Power BI Volume Watch](../screenshots/demo_step11_powerbi_volume_watch.png)

---

âœ… DÃ©mo end-to-end documentÃ©e (version actuelle)

- ChaÃ®ne couverte: extraction â†’ ingestion â†’ orchestration ADF â†’ quality engine â†’ consolidation `vigie_ctrl` â†’ visualisation Power BI.
- Ã‰volution prÃ©vue: drill-downs Power BI par catÃ©gorie de problÃ¨me (volume, SLA, source dâ€™alerte).

---

Ã‰tapes suivantes Ã  documenter au fil des screenshots (optionnel):

1. Drill-down Power BI par problÃ¨me (volume/SLA/source)
