# ‚öôÔ∏è Stored Procedures

Les proc√©dures stock√©es sont les points d'int√©gration pour les calculateurs de SLA, le lifecycle du framework et la validation de qualit√©.

## üèõÔ∏è Architecture: Azure SQL vs Synapse

**Azure SQL Database** (vigie_ctrl):
- Proc√©dures de **lifecycle** et **orchestration**
- Calculs **SLA** et **quality summary**
- Validation **structurelle** (hash comparison)
- Localisation: `sql/procedures/`

**Synapse Serverless** (pool SQL):
- Proc√©dures d'**inspection** des fichiers Parquet/CSV
- Tests de **qualit√©** (ROW_COUNT, MIN_MAX, CHECKSUM)
- D√©tection **structurelle** runtime
- Localisation: `sql/synapse/procedures/`

## Convention de vocabulaire (cross-docs)

Termes canoniques utilis√©s dans la documentation : `p_ctrl_id`, `p_dataset`, `p_periodicity`, `p_extraction_date`.

| Canonique (docs) | Param√®tre SQL (SP) | Param√®tre ADF | Colonne SQL fr√©quente |
|---|---|---|---|
| `p_ctrl_id` | `@ctrl_id` | `p_ctrl_id` | `ctrl_id` |
| `p_dataset` | `@dataset` | `p_dataset` / `p_table` | `dataset_name` |
| `p_periodicity` | `@periodicity` | `p_periodicity` / `p_period` | `periodicity` |
| `p_extraction_date` | `@extraction_date` | `p_extraction_date` | `extraction_date` |

| Proc√©dure | R√¥le | Moteur | Profil SLA | Formule |
|---|---|---|---|---|
| `SP_Set_Start_TS_OEIL` | ‚è±Ô∏è Lifecycle | ‚Äî | ‚Äî | Cr√©e la ligne si elle n'existe pas, pose `start_ts`. Idempotent. |
| `SP_Set_End_TS_OEIL` | ‚è±Ô∏è Lifecycle | **OEIL** | `EXECUTION_TYPE` | Pose `end_ts`, calcule `duration_sec`, √©value SLA OEIL. |
| `SP_Compute_SLA_ADF` | üìä Calcul | **ADF** | `EXECUTION_TYPE` | Lit m√©triques KQL (`row_count`, `duration`), calcule SLA volume-based. |
| `SP_Compute_SLA_SYNAPSE` | üìä Calcul | **SYNAPSE** | `EXECUTION_TYPE` | Lit dur√©e Synapse, calcule SLA fixed overhead. |
| `SP_Compute_SLA_OEIL` | üìä Calcul | **OEIL** | `EXECUTION_TYPE` | Appel√© en interne par `SP_Set_End`, mais peut √™tre rappel√© pour recalcul. |
| `SP_Compute_SLA_Vigie` | üìä Calcul | **GLOBAL** | `DATASET` (futur) | Calcul SLA global par dataset (plus fin que par moteur). |
| `SP_Compute_Quality_Summary` | üìä Calcul | **QUALITY** | ‚Äî | Agr√®ge les r√©sultats de `vigie_integrity_result` et met √† jour les champs `quality_*` dans `vigie_ctrl`. |
| `SP_Update_VigieCtrl_FromIntegrity` | üîÅ Sync qualit√© ‚Üí run | **OEIL** | ‚Äî | Reprend le dernier `ROW_COUNT` de `vigie_integrity_result`, compare √† `expected_rows` et met √† jour `vigie_ctrl` (bronze/parquet/timestamps/status). |
| `SP_Verify_Ctrl_Hash_V1` | üîí Int√©grit√© CTRL | **OEIL** | ‚Äî | V√©rifie la coh√©rence du hash canonique CTRL et met √† jour `payload_hash_match` dans `vigie_ctrl`. |
| `SP_REFRESH_STRUCTURAL_HASH` | üîÑ Refresh hash | **CTRL** | ‚Äî | Recalcule le hash structurel SHA-256 bas√© sur le mapping JSON d√©terministe des datasets et colonnes. |
| `SP_GET_CONTRACT_STRUCTURE_HASH` (**Azure SQL**) | üîç Get contract hash | **CTRL** | ‚Äî | G√©n√®re hash SHA-256 du contrat structurel (ordinal + nom + type normalis√©) depuis `ctrl.dataset_column`. |
| `SP_GET_DETECTED_STRUCTURE_HASH` (**Synapse**) | üîé Get detected hash | **QUALITY** | ‚Äî | G√©n√®re hash SHA-256 hex (`VARCHAR(64)`) de la structure d√©tect√©e (ordinal + nom + type r√©el) depuis `INFORMATION_SCHEMA.COLUMNS` (external table). |
| `SP_CHECKSUM_STRUCTURE_COMPARE` (**Azure SQL**) | ‚úÖ Validate structure | **QUALITY** | ‚Äî | Compare hash contractuel vs d√©tect√©. **THROW 50001** si FAIL, sinon PASS et continue. |

## Parameters and Logic

### `SP_Set_Start_TS_OEIL`

```sql
@ctrl_id NVARCHAR(200),
@dataset NVARCHAR(100),
@periodicity NVARCHAR(10),
@extraction_date DATE
```

1.  **INSERT** si `ctrl_id` n'existe pas.
2.  **UPDATE** `start_ts` si NULL.
3.  Set `status_global` = 'IN_PROGRESS'.

### `SP_Set_End_TS_OEIL`

```sql
@ctrl_id NVARCHAR(200)
```

1.  Capture `SYSUTCDATETIME()` ‚Üí `end_ts`.
2.  Calcule dur√©e totale.
3.  Charge profil SLA (OEIL).
4.  √âvalue PASS/FAIL.
5.  Set `status_global` = 'SUCCEEDED' (selon outcome).

### `SP_Compute_SLA_ADF`

```sql
@ctrl_id NVARCHAR(200),
@row_count INT,
@duration_sec INT
```

1.  Charge profil SLA (ADF).
2.  Calcule `expected = overhead + (rows/1000 * cost)`.
3.  Compare `duration` vs `threshold`.
4.  Update `vigie_ctrl` avec verdict.

### `SP_Insert_VigieIntegrityResult`

```sql
@ctrl_id NVARCHAR(150),
@dataset_name NVARCHAR(150),
@test_code NVARCHAR(50),
@column_name NVARCHAR(150) = NULL,

@bronze_value FLOAT = NULL,
@bronze_aux_value FLOAT = NULL,
@parquet_value FLOAT = NULL,
@parquet_aux_value FLOAT = NULL,

@status NVARCHAR(30),
@execution_time_ms INT = NULL,

@synapse_start_ts DATETIME2 = NULL,
@synapse_end_ts DATETIME2 = NULL,

@observed_value_text NVARCHAR(500) = NULL,
@reference_value_text NVARCHAR(500) = NULL
```

1.  Calcule `delta_value = ABS(@bronze_value - @parquet_value)` quand les 2 valeurs num√©riques sont pr√©sentes.
2.  S√©curise `synapse_start_ts` / `synapse_end_ts` (fallback `SYSUTCDATETIME()` et correction si `end < start`).
3.  Ins√®re la ligne dans `dbo.vigie_integrity_result` avec :
	- valeurs num√©riques (`observed_value_num`, `reference_value_num`, etc.)
	- valeurs texte (`observed_value_text`, `reference_value_text`) pour les tests non num√©riques (ex: checksum)
	- statut, timing et timestamps.

### `SP_Compute_Quality_Summary`

```sql
@ctrl_id NVARCHAR(150)
```

1.  Agr√®ge les statuts (`PASS`, `FAIL`, `WARNING`) de `dbo.vigie_integrity_result` pour `@ctrl_id`.
2.  Calcule les compteurs qualit√© :
	- `quality_tests_total`
	- `quality_tests_pass`
	- `quality_tests_fail`
	- `quality_tests_warning`
3.  D√©termine `quality_status_global` selon la r√®gle:
	- `UNKNOWN` si aucun test
	- `FAIL` si au moins un fail
	- `WARNING` sinon si au moins un warning
	- `PASS` sinon
4.  Met √† jour `dbo.vigie_ctrl` pour le `ctrl_id` cibl√©.

### `SP_Update_VigieCtrl_FromIntegrity`

```sql
@ctrl_id NVARCHAR(150)
```

1.  Lit la derni√®re ligne `ROW_COUNT` de `dbo.vigie_integrity_result` pour `@ctrl_id`.
2.  Calcule `synapse_duration_sec = DATEDIFF(SECOND, synapse_start_ts, synapse_end_ts)`.
3.  Lit `expected_rows` dans `dbo.vigie_ctrl`.
4.  Met √† jour `dbo.vigie_ctrl` avec :
	- `bronze_rows` (depuis `observed_value_num`) + `bronze_delta` + `bronze_status`
	- `parquet_rows` (depuis `reference_value_num`) + `parquet_delta` + `parquet_status`
	- `synapse_start_ts`, `synapse_end_ts`, `synapse_duration_sec`
	- `status` (depuis le `status` d'int√©grit√©)

Convention importante :

- Pour le test `ROW_COUNT`, la valeur Bronze est port√©e par `observed_value_num` et la valeur Parquet par `reference_value_num`.

R√®gle de r√©duction (tests multiples) [Implemented]:

- Si plusieurs r√©sultats existent pour un m√™me `ctrl_id` + `ROW_COUNT`, la proc√©dure prend le plus r√©cent.
- Le choix est explicite (`TOP 1 ... ORDER BY integrity_result_id DESC`) pour √©viter toute d√©pendance √† l'ordre implicite d'insertion.

### `SP_Verify_Ctrl_Hash_V1`

```sql
@ctrl_id NVARCHAR(200)
```

Logique impl√©ment√©e (V1):

1. Lit `dataset`, `periodicity`, `extraction_date`, `expected_rows`, `payload_hash_sha256` depuis `dbo.vigie_ctrl`.
2. Reconstruit `payload_canonical` au format exact:
	- `dataset|periodicity|YYYY-MM-DD|expected_rows`
3. Recalcule `@computed_hash` en `SHA2_256` (hex lowercase, sans pr√©fixe `0x`) via:
	- `HASHBYTES('SHA2_256', CAST(@payload_canonical AS VARCHAR(MAX)))`
	- `CONVERT(VARCHAR(64), ..., 2)` puis `LOWER(...)`
4. Compare `LOWER(@stored_hash)` au hash recalcul√©.
5. Met √† jour `dbo.vigie_ctrl` avec:
	- `payload_canonical`
	- `payload_hash_version = 1`
	- `payload_hash_match` (`1` si match, sinon `0`)
	- `alert_flag` (`0` si match, sinon `1`)
	- `alert_reason` = `HASH_OK` / `CTRL_HASH_MISMATCH` / `MISSING_HASH`

Contrat orchestration actuel:

- Si `payload_hash_match = 1`, le run continue vers `PL_Oeil_Core`.
- Si `payload_hash_match = 0`, le run est stopp√© (`CTRL_HASH_MISMATCH`).

Exemple canonique V1:

`clients|Q|2026-07-01|1199`

### `SP_REFRESH_STRUCTURAL_HASH`

```sql
@dataset_name VARCHAR(100) = NULL  -- NULL = tous les datasets
```

1. Parcourt tous les datasets actifs (ou uniquement `@dataset_name` si sp√©cifi√©).
2. Pour chaque dataset, g√©n√®re un JSON d√©terministe incluant:
	- `dataset_name`, `source_system`, `mapping_version`
	- Liste ordonn√©e des colonnes avec leurs propri√©t√©s (ordinal, name, types, nullable, keys, tokenization, normalization)
3. Calcule le hash SHA-256 du JSON.
4. Met √† jour `ctrl.dataset.structural_hash` avec la valeur calcul√©e.

Utilis√© pour d√©tecter les changements de structure/mapping et invalider les runs bas√©s sur une version obsol√®te du sch√©ma.

### `SP_GET_CONTRACT_STRUCTURE_HASH` (**Azure SQL**)

```sql
@dataset_name VARCHAR(100)
```

1. Lit la structure **contractuelle** depuis `ctrl.dataset` et `ctrl.dataset_column`.
2. G√©n√®re un JSON d√©terministe avec:
	- `ordinal` (ordre des colonnes)
	- `name` (nom de colonne)
	- `type_detected` (type normalis√©: `int`, `varchar`, `date`, etc.)
3. Calcule le hash SHA-256 du JSON.
4. Retourne `contract_structure_json` et `contract_structural_hash`.

Normalisation des types pour garantir comparaison:
- `VARCHAR(n)` ‚Üí `varchar`
- `CHAR(n)` ‚Üí `char`
- `DECIMAL(p,s)` ‚Üí `decimal`
- `DATETIME2` / `DATETIME` ‚Üí `datetime2`

### `SP_GET_DETECTED_STRUCTURE_HASH` (**Synapse Serverless**)

```sql
@dataset_name NVARCHAR(150)
```

1. Cible la table externe `ext.{dataset_name}_std` (ex: `ext.clients_std`).
2. Interroge `INFORMATION_SCHEMA.COLUMNS` pour obtenir la structure **r√©elle** du Parquet.
3. G√©n√®re un JSON d√©terministe avec:
	- `ordinal` (ordre effectif des colonnes)
	- `name` (nom effectif)
	- `type_detected` (type SQL d√©tect√© par Synapse)
4. Calcule le hash SHA-256 du JSON et le convertit en hex (`VARCHAR(64)`).
5. Retourne `detected_structure_json` et `detected_structural_hash` (hex).

**Note critique**: Cette SP s'ex√©cute **dans Synapse**, pas dans Azure SQL.

### `SP_CHECKSUM_STRUCTURE_COMPARE` (**Azure SQL**)

```sql
@ctrl_id        NVARCHAR(150),
@dataset_name   NVARCHAR(150),
@contract_hash  VARBINARY(32),
@detected_hash  VARBINARY(32)
```

1. Compare `@contract_hash` (attendu) vs `@detected_hash` (r√©el).
2. Ins√®re r√©sultat dans `dbo.vigie_integrity_result`:
	- `test_code = 'CHECKSUM_STRUCTURE'`
	- `observed_value_text` = hash d√©tect√© (hex)
	- `reference_value_text` = hash contractuel (hex)
	- `status` = `PASS` / `FAIL`
3. **Si FAIL**: `THROW 50001` ‚Üí bloque le pipeline imm√©diatement.
4. **Si PASS**: retourne r√©sum√© et continue.

**R√¥le critique**: Point de contr√¥le **pr√©-qualit√©**. Si la structure ne match pas (ordre colonnes, types, noms), le pipeline s'arr√™te **avant** les tests ROW_COUNT/MIN_MAX/CHECKSUM pour √©viter erreurs downstream.

## üîí Concurrency & Idempotence Guarantees

- La PK (`ctrl_id`) prot√®ge contre les doubles insertions de run logique dans `vigie_ctrl`.
- `SP_Set_Start_TS_OEIL` ne r√©√©crit pas `start_ts` si d√©j√† pos√©.
- `SP_Set_End_TS_OEIL` ne r√©√©crit pas `end_ts` si d√©j√† pos√© (comportement attendu d'idempotence lifecycle).
- `SP_Update_VigieCtrl_FromIntegrity` applique une r√©duction `latest` (dernier `ROW_COUNT` via `TOP 1 ... ORDER BY integrity_result_id DESC`).

## Mini diagrammes (SP critiques)

### 0) **Validation Structurelle** (nouveau flux pr√©-qualit√©)

```mermaid
flowchart TD
    A[PL_Oeil_Quality_Engine d√©marr√©] --> B[SP_GET_CONTRACT_STRUCTURE_HASH<br/>Azure SQL]
    B --> C{Lit ctrl.dataset_column}
    C --> D[JSON contract: ordinal+name+type_normalized]
    D --> E[contract_hash = SHA2_256]
    
    A --> F[SP_GET_DETECTED_STRUCTURE_HASH<br/>Synapse Serverless]
    F --> G{Lit INFORMATION_SCHEMA.COLUMNS<br/>ext.dataset_std}
    G --> H[JSON detected: ordinal+name+type_detected]
    H --> I[detected_hash = SHA2_256]
    
    E --> J[SP_CHECKSUM_STRUCTURE_COMPARE<br/>Azure SQL]
    I --> J
    
    J --> K{contract_hash == detected_hash ?}
    K -->|PASS| L[INSERT vigie_integrity_result<br/>test_code=CHECKSUM_STRUCTURE<br/>status=PASS]
    L --> M[Continue vers ForEach_Policy]
    M --> N[Tests qualit√©: ROW_COUNT, MIN_MAX, CHECKSUM...]
    
    K -->|FAIL| O[INSERT vigie_integrity_result<br/>status=FAIL]
    O --> P[THROW 50001:<br/>CHECKSUM_STRUCTURE FAILED]
    P --> Q[‚ùå Pipeline arr√™t√©]
    
    style P fill:#ff6b6b
    style Q fill:#ff6b6b
    style M fill:#51cf66
    style N fill:#51cf66
```

**Impact**: Cette validation structurelle **bloque** le pipeline si:
- Ordre des colonnes diff√©rent
- Types SQL incompatibles (ex: `int` vs `varchar`)
- Colonnes manquantes ou ajout√©es

Cela √©vite les erreurs downstream et garantit la conformit√© au contrat avant d'ex√©cuter les tests co√ªteux.

### 1) `SP_Set_Start_TS_OEIL`

```mermaid
flowchart TD
	A[Inputs: p_ctrl_id, p_dataset, p_periodicity, p_extraction_date] --> B{p_ctrl_id existe ?}
	B -->|Non| C[INSERT ligne vigie_ctrl]
	B -->|Oui| D[Conserver ligne existante]
	C --> E{start_ts NULL ?}
	D --> E
	E -->|Oui| F[UPDATE start_ts = SYSUTCDATETIME]
	E -->|Non| G[No-op start_ts]
	F --> H[UPDATE status_global = IN_PROGRESS]
	G --> H
	H --> I[(Output: vigie_ctrl start_ts/status)]
```

### 2) `SP_Set_End_TS_OEIL`

```mermaid
flowchart TD
	A[Input: p_ctrl_id] --> B[UPDATE end_ts = SYSUTCDATETIME]
	B --> C[Compute duration_sec = end_ts - start_ts]
	C --> D[Call SP_Compute_SLA_OEIL]
	D --> E[Set status_global selon verdict]
	E --> F[(Output: vigie_ctrl end_ts/duration/SLA)]
```

### 3) `SP_Compute_SLA_OEIL`

```mermaid
flowchart TD
	A[Input: p_ctrl_id] --> B[Lookup profil SLA moteur=OEIL]
	B --> C[Read duration_sec courant]
	C --> D[Compute expected/threshold]
	D --> E{duration <= threshold ?}
	E -->|Oui| F[Set sla_status = PASS]
	E -->|Non| G[Set sla_status = FAIL]
	F --> H[(Output: vigie_ctrl SLA OEIL)]
	G --> H
```

### 4) `SP_Insert_VigieIntegrityResult`

```mermaid
flowchart TD
	A[Inputs: ctrl_id/dataset/test + observed/reference + timestamps Synapse] --> B[Compute delta = ABS(observed-reference)]
	B --> C[S√©curiser synapse_start_ts/synapse_end_ts]
	C --> D[INSERT ligne dbo.vigie_integrity_result]
	D --> E[(Output: trace d'int√©grit√© persist√©e)]
```

### 5) `SP_Update_VigieCtrl_FromIntegrity`

```mermaid
flowchart TD
	A[Input: p_ctrl_id] --> B[SELECT TOP 1 ROW_COUNT dans vigie_integrity_result]
	B --> C[Map observed/reference -> bronze/parquet]
	C --> D[Lookup expected_rows dans vigie_ctrl]
	D --> E[Compute delta/status bronze+parquet]
	E --> F[UPDATE dbo.vigie_ctrl]
	F --> G[(Output: sync run metrics depuis int√©grit√©)]
```

## Pipeline Qualit√© (Int√©grit√©) ‚Äî Statut actuel

Le pipeline de qualit√© est op√©rationnel avec **2 policies activ√©es** :

- `ROW_COUNT`
- `MIN_MAX`

### Proc√©dures actuellement utilis√©es

- Azure SQL : `dbo.SP_Insert_VigieIntegrityResult`
- Azure SQL : `dbo.SP_Update_VigieCtrl_FromIntegrity`
- Synapse : `ctrl.SP_OEIL_ROWCOUNT`
- Synapse : `ctrl.SP_OEIL_MIN_MAX`
- Synapse : `ctrl.SP_OEIL_CHECKSUM`

### Proc√©dure Synapse ajout√©e (checksum)

`ctrl.SP_OEIL_CHECKSUM` compare un hash SHA-256 d√©terministe Bronze vs Parquet pour une colonne donn√©e.

Signature:

```sql
ctrl.SP_OEIL_CHECKSUM(
	@bronze_path NVARCHAR(500),
	@parquet_path NVARCHAR(500),
	@column_name NVARCHAR(150)
)
```

Sortie:

- `bronze_checksum`
- `parquet_checksum`
- `integrity_status` (`PASS` / `FAIL`)

### R√©sultats observ√©s (exemple valid√©)

Exemple sur `ctrl_id = clients_2026-05-01_Q` :

| integrity_result_id | test_code | column_name | observed_value_num | observed_value_aux_num | reference_value_num | reference_value_aux_num | delta_value | status | execution_time_ms | synapse_start_ts | synapse_end_ts |
|---|---|---|---:|---:|---:|---:|---:|---|---:|---|---|
| 6 | MIN_MAX | client_id | 101113 | 999862 | 101113 | 999862 | 0 | PASS | 3 | 2026-02-19 13:29:21 | 2026-02-19 13:29:50 |
| 5 | ROW_COUNT | ROW_COUNT | 872 | 0 | 872 | 0 | 0 | PASS | 3 | 2026-02-19 13:29:21 | 2026-02-19 13:29:50 |

Notes :

- Les r√©sultats sont persist√©s dans `dbo.vigie_integrity_result` via la nouvelle structure `observed/reference`.
- Les tests textuels (ex: `CHECKSUM`) renseignent `observed_value_text` et `reference_value_text`.
- Si `synapse_start_ts` ou `synapse_end_ts` est absent, la SP les initialise √† `SYSUTCDATETIME()`.
- Le d√©tail d'orchestration (JSON pipeline + screenshot) sera document√© dans une section d√©di√©e d√®s int√©gration des artefacts ADF.

